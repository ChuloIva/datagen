{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Cognitive Action Training Data Generator\n",
    "\n",
    "This notebook generates high-quality training data for cognitive action recognition using Ollama locally or via API.\n",
    "\n",
    "**Based on Scientific Taxonomies:**\n",
    "- Bloom's Taxonomy (cognitive processes)\n",
    "- Guilford's Structure of Intellect\n",
    "- Krathwohl's Affective Domain\n",
    "- Gross's Emotion Regulation Model\n",
    "- Metacognitive Process Frameworks\n",
    "\n",
    "**Target:** 100,000+ diverse examples of explicit cognitive and psychological actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install requests pandas numpy tqdm matplotlib seaborn\n",
    "\n",
    "# If running locally with Ollama installed:\n",
    "# !pip install ollama\n",
    "\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload_files"
   },
   "source": [
    "## 2. Upload Supporting Files\n",
    "\n",
    "Upload the following files to your Colab environment:\n",
    "- `variable_pools.py`\n",
    "- `prompt_templates.py` \n",
    "- `data_generator.py`\n",
    "\n",
    "Or run the cells below to create them directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_variable_pools"
   },
   "outputs": [],
   "source": [
    "%%writefile variable_pools.py\n",
    "\"\"\"\n",
    "Variable Pools for Cognitive Action Training Data Generation\n",
    "Based on scientific taxonomies from cognitive psychology and emotion research\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "\n",
    "# =============================================================================\n",
    "# COGNITIVE ACTIONS (Based on Scientific Taxonomies)\n",
    "# =============================================================================\n",
    "\n",
    "# Combined from multiple taxonomies: original instructions + scientific frameworks\n",
    "COGNITIVE_ACTIONS = {\n",
    "    # Original Core Actions\n",
    "    \"reconsidering\": \"reconsidering a belief or decision\",\n",
    "    \"reframing\": \"reframing a situation or perspective\",\n",
    "    \"noticing\": \"noticing a pattern, feeling, or dynamic\",\n",
    "    \"perspective_taking\": \"taking another's perspective or temporal view\",\n",
    "    \"questioning\": \"questioning an assumption or belief\",\n",
    "    \"abstracting\": \"abstracting from specifics to general patterns\",\n",
    "    \"concretizing\": \"making abstract concepts concrete and specific\",\n",
    "    \"connecting\": \"connecting disparate ideas or experiences\",\n",
    "    \"distinguishing\": \"distinguishing between previously conflated concepts\",\n",
    "    \"updating_beliefs\": \"updating mental models or beliefs\",\n",
    "    \"suspending_judgment\": \"suspending judgment and staying with uncertainty\",\n",
    "    \"pattern_recognition\": \"recognizing recurring patterns across situations\",\n",
    "    \"zooming_out\": \"zooming out for broader context\",\n",
    "    \"zooming_in\": \"zooming in on specific details\",\n",
    "    \"analogical_thinking\": \"drawing analogies between domains\",\n",
    "    \"counterfactual_reasoning\": \"engaging in 'what if' thinking\",\n",
    "    \"hypothesis_generation\": \"generating possible explanations\",\n",
    "    \"meta_awareness\": \"reflecting on one's own thinking process\",\n",
    "    \"accepting\": \"accepting and letting go of control\",\n",
    "\n",
    "    # From Bloom's Taxonomy\n",
    "    \"remembering\": \"recalling relevant information or experiences\",\n",
    "    \"understanding\": \"interpreting and explaining meaning\",\n",
    "    \"applying\": \"using knowledge in new situations\",\n",
    "    \"analyzing\": \"breaking down into components\",\n",
    "    \"evaluating\": \"making judgments about value or effectiveness\",\n",
    "    \"creating\": \"generating new ideas or solutions\",\n",
    "\n",
    "    # From Guilford's Structure of Intellect\n",
    "    \"divergent_thinking\": \"generating multiple creative solutions\",\n",
    "    \"convergent_thinking\": \"finding the single best solution\",\n",
    "    \"cognition_awareness\": \"becoming aware and comprehending\",\n",
    "\n",
    "    # Metacognitive Operations\n",
    "    \"metacognitive_monitoring\": \"tracking one's own comprehension\",\n",
    "    \"metacognitive_regulation\": \"adjusting thinking strategies\",\n",
    "    \"self_questioning\": \"interrogating one's own understanding\",\n",
    "\n",
    "    # Emotional/Affective Operations (from taxonomies)\n",
    "    \"emotional_reappraisal\": \"reinterpreting emotional meaning\",\n",
    "    \"emotion_receiving\": \"becoming aware of emotions\",\n",
    "    \"emotion_responding\": \"actively engaging with emotions\",\n",
    "    \"emotion_valuing\": \"attaching worth to emotional experiences\",\n",
    "    \"emotion_organizing\": \"integrating conflicting emotions\",\n",
    "    \"emotion_characterizing\": \"aligning emotions with core values\",\n",
    "    \"situation_selection\": \"choosing emotional contexts deliberately\",\n",
    "    \"situation_modification\": \"changing circumstances to regulate emotion\",\n",
    "    \"attentional_deployment\": \"directing attention for emotional regulation\",\n",
    "    \"response_modulation\": \"modifying emotional expression\",\n",
    "    \"emotion_perception\": \"identifying emotions in self/others\",\n",
    "    \"emotion_facilitation\": \"using emotions to enhance thinking\",\n",
    "    \"emotion_understanding\": \"comprehending emotional complexity\",\n",
    "    \"emotion_management\": \"regulating emotions in self/others\"\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# SUBJECTS (Who is doing the thinking)\n",
    "# =============================================================================\n",
    "\n",
    "SUBJECTS = [\n",
    "    # Professional Roles\n",
    "    \"a software developer\", \"a teacher\", \"a therapist\", \"a manager\", \"a researcher\",\n",
    "    \"a scientist\", \"a doctor\", \"a lawyer\", \"a consultant\", \"a designer\",\n",
    "    \"an engineer\", \"a writer\", \"an artist\", \"a musician\", \"an entrepreneur\",\n",
    "    \"a nurse\", \"a social worker\", \"a coach\", \"a mentor\", \"a leader\",\n",
    "\n",
    "    # Life Stages/Demographics\n",
    "    \"someone in their early 20s\", \"someone in their 30s\", \"someone in their 40s\",\n",
    "    \"someone in their 50s\", \"someone in their 60s\", \"a recent graduate\",\n",
    "    \"a parent\", \"a grandparent\", \"a student\", \"a retiree\",\n",
    "\n",
    "    # Relationship Roles\n",
    "    \"a partner in a relationship\", \"a friend\", \"a colleague\", \"a team member\",\n",
    "    \"a sibling\", \"a child reflecting on parents\", \"a mentor\", \"a mentee\",\n",
    "\n",
    "    # Life Situations\n",
    "    \"someone grieving a loss\", \"someone facing a major transition\",\n",
    "    \"someone dealing with success\", \"someone processing failure\",\n",
    "    \"a person in therapy\", \"someone in recovery\", \"a career changer\",\n",
    "    \"someone learning a new skill\", \"a person facing illness\",\n",
    "    \"someone in conflict\", \"a person seeking growth\"\n",
    "]\n",
    "\n",
    "# =============================================================================\n",
    "# DOMAINS (Context areas)\n",
    "# =============================================================================\n",
    "\n",
    "DOMAINS = [\n",
    "    \"personal relationships\", \"romantic relationships\", \"family dynamics\",\n",
    "    \"friendships\", \"career decisions\", \"professional development\",\n",
    "    \"creative work\", \"artistic expression\", \"scientific research\",\n",
    "    \"academic learning\", \"moral and ethical dilemmas\", \"health and wellness\",\n",
    "    \"financial planning\", \"investment decisions\", \"conflict resolution\",\n",
    "    \"identity and self-concept\", \"parenting and caregiving\", \"leadership challenges\",\n",
    "    \"team dynamics\", \"communication challenges\", \"goal setting and achievement\",\n",
    "    \"dealing with failure\", \"processing success\", \"daily mundane decisions\",\n",
    "    \"philosophical questions\", \"spiritual exploration\", \"time management\",\n",
    "    \"personal growth\", \"therapy and healing\", \"addiction recovery\",\n",
    "    \"grief and loss\", \"major life transitions\", \"retirement planning\",\n",
    "    \"educational choices\", \"political beliefs\", \"social justice issues\"\n",
    "]\n",
    "\n",
    "# =============================================================================\n",
    "# CONTEXT DETAILS (Specific scenarios for each domain)\n",
    "# =============================================================================\n",
    "\n",
    "CONTEXT_DETAILS = {\n",
    "    \"personal relationships\": [\n",
    "        \"after a difficult conversation with a partner\",\n",
    "        \"noticing a recurring conflict pattern with a family member\",\n",
    "        \"considering whether to reconnect with an old friend\",\n",
    "        \"processing feedback from someone close\",\n",
    "        \"dealing with feeling excluded from a social group\",\n",
    "        \"navigating a boundary issue with a friend\",\n",
    "        \"after a misunderstanding was clarified\",\n",
    "        \"considering ending a toxic relationship\",\n",
    "        \"noticing how they communicate differently with different people\",\n",
    "        \"reflecting on a repeated argument pattern\"\n",
    "    ],\n",
    "\n",
    "    \"career decisions\": [\n",
    "        \"after receiving a job offer from a different field\",\n",
    "        \"considering a major career pivot\",\n",
    "        \"processing harsh feedback from a supervisor\",\n",
    "        \"deciding whether to speak up about workplace issues\",\n",
    "        \"evaluating why a project failed\",\n",
    "        \"thinking about asking for a promotion\",\n",
    "        \"after being passed over for advancement\",\n",
    "        \"considering starting their own business\",\n",
    "        \"dealing with imposter syndrome at work\",\n",
    "        \"reflecting on work-life balance priorities\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Add more context details for other domains\n",
    "for domain in DOMAINS:\n",
    "    if domain not in CONTEXT_DETAILS:\n",
    "        CONTEXT_DETAILS[domain] = [\n",
    "            f\"facing a significant decision about {domain}\",\n",
    "            f\"processing unexpected developments in {domain}\",\n",
    "            f\"reflecting on patterns in {domain}\",\n",
    "            f\"considering changes to their approach in {domain}\",\n",
    "            f\"dealing with conflict or tension in {domain}\"\n",
    "        ]\n",
    "\n",
    "# =============================================================================\n",
    "# ADDITIONAL VARIABLES\n",
    "# =============================================================================\n",
    "\n",
    "TRIGGERS = [\n",
    "    \"reading an article that contradicts their worldview\",\n",
    "    \"receiving unexpected feedback from someone they trust\",\n",
    "    \"noticing their physical or emotional reaction to something\",\n",
    "    \"having a meaningful conversation with someone\",\n",
    "    \"experiencing an unexpected setback or failure\",\n",
    "    \"achieving success in an unexpected way\",\n",
    "    \"witnessing someone else's perspective on the same issue\",\n",
    "    \"having quiet time for reflection during a walk or shower\",\n",
    "    \"facing a deadline that forces clarity\",\n",
    "    \"encountering a similar situation to one from their past\"\n",
    "]\n",
    "\n",
    "EMOTIONAL_STATES = [\n",
    "    \"feeling frustrated and stuck\", \"experiencing confusion and uncertainty\",\n",
    "    \"feeling defensive about their position\", \"in a calm and reflective mood\",\n",
    "    \"feeling anxious about the implications\", \"experiencing genuine curiosity\",\n",
    "    \"feeling disappointed by outcomes\", \"in a moment of unexpected clarity\",\n",
    "    \"feeling overwhelmed by options\", \"experiencing relief after stress\"\n",
    "]\n",
    "\n",
    "LANGUAGE_STYLES = [\n",
    "    \"casual and conversational\", \"introspective and literary\",\n",
    "    \"straightforward and direct\", \"tentative and exploratory\",\n",
    "    \"confident and declarative\", \"stream-of-consciousness style\",\n",
    "    \"analytical and precise\", \"emotional and expressive\"\n",
    "]\n",
    "\n",
    "UNIQUE_ANGLES = [\n",
    "    \"include a specific sensory detail that triggered the insight\",\n",
    "    \"show the cognitive process taking time rather than being instant\",\n",
    "    \"include self-doubt about the cognitive process itself\",\n",
    "    \"show a partial or incomplete cognitive shift\",\n",
    "    \"include resistance or pushback before the mental shift\",\n",
    "    \"make the scenario very mundane and everyday\",\n",
    "    \"show it happening in a specific physical location\",\n",
    "    \"include another person's influence on the thinking\"\n",
    "]\n",
    "\n",
    "COMPLEXITY_LEVELS = {\n",
    "    \"simple\": \"Single clear cognitive action, straightforward scenario, obvious outcome\",\n",
    "    \"moderate\": \"Multiple factors at play, some ambiguity, partial clarity\",\n",
    "    \"complex\": \"Multiple interacting cognitive actions, high uncertainty, conflicting considerations, no clear resolution\"\n",
    "}\n",
    "\n",
    "PERSPECTIVES = [\n",
    "    \"first-person present tense ('I'm noticing right now...')\",\n",
    "    \"first-person past reflective ('I realized later that I had been...')\",\n",
    "    \"first-person future conditional ('I'll need to reconsider when...')\",\n",
    "    \"second-person coaching ('You might try reframing...')\",\n",
    "    \"third-person observation ('She began to reconsider...')\",\n",
    "    \"internal monologue with self-talk\",\n",
    "    \"metacognitive commentary ('My thought process here is...')\"\n",
    "]\n",
    "\n",
    "# =============================================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def get_random_selection():\n",
    "    \"\"\"Get a random selection of variables for prompt generation\"\"\"\n",
    "    return {\n",
    "        'cognitive_action': random.choice(list(COGNITIVE_ACTIONS.keys())),\n",
    "        'subject': random.choice(SUBJECTS),\n",
    "        'domain': random.choice(DOMAINS),\n",
    "        'trigger': random.choice(TRIGGERS),\n",
    "        'emotional_state': random.choice(EMOTIONAL_STATES),\n",
    "        'language_style': random.choice(LANGUAGE_STYLES),\n",
    "        'unique_angle': random.choice(UNIQUE_ANGLES),\n",
    "        'complexity_level': random.choice(list(COMPLEXITY_LEVELS.keys())),\n",
    "        'perspective': random.choice(PERSPECTIVES)\n",
    "    }\n",
    "\n",
    "def get_context_detail(domain):\n",
    "    \"\"\"Get a specific context detail for a domain\"\"\"\n",
    "    return random.choice(CONTEXT_DETAILS.get(domain, CONTEXT_DETAILS[\"personal relationships\"]))\n",
    "\n",
    "def get_cognitive_action_chains(n=3):\n",
    "    \"\"\"Get a sequence of cognitive actions for chain examples\"\"\"\n",
    "    actions = random.sample(list(COGNITIVE_ACTIONS.keys()), n)\n",
    "    return actions\n",
    "\n",
    "print(\"Variable pools loaded successfully!\")\n",
    "print(f\"Total cognitive actions: {len(COGNITIVE_ACTIONS)}\")\n",
    "print(f\"Total domains: {len(DOMAINS)}\")\n",
    "print(f\"Total subjects: {len(SUBJECTS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_prompt_templates"
   },
   "outputs": [],
   "source": [
    "%%writefile prompt_templates.py\n",
    "\"\"\"\n",
    "Prompt Templates for Cognitive Action Training Data Generation\n",
    "Based on instructions2.md template system architecture\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "from variable_pools import *\n",
    "\n",
    "# =============================================================================\n",
    "# SINGLE COGNITIVE ACTION TEMPLATES\n",
    "# =============================================================================\n",
    "\n",
    "SINGLE_ACTION_TEMPLATES = [\n",
    "    # Template 1: Scenario-Based\n",
    "    \"\"\"Generate 1 example (2-4 sentences) showing someone {cognitive_action_desc} in this specific scenario:\n",
    "\n",
    "Scenario: {subject} is {situation} and experiences {trigger}. They engage in {cognitive_action_desc}.\n",
    "\n",
    "Requirements:\n",
    "- Domain: {domain}\n",
    "- Emotional context: {emotional_state}\n",
    "- Show the cognitive process explicitly\n",
    "- Use {language_style} language\n",
    "- Focus angle: {unique_angle}\n",
    "- Complexity: {complexity_level}\n",
    "\n",
    "Output only the example text, no preamble.\"\"\",\n",
    "\n",
    "    # Template 2: Before/After\n",
    "    \"\"\"Generate 1 example (2-4 sentences) showing {cognitive_action_desc} by contrasting before and after states:\n",
    "\n",
    "Context: {domain} situation involving {context_detail}\n",
    "Before state: {initial_state}\n",
    "Cognitive action: {cognitive_action_desc}\n",
    "After state: {result_direction}\n",
    "\n",
    "Requirements:\n",
    "- Subject: {subject}\n",
    "- Complexity: {complexity_level}\n",
    "- Avoid cliché phrasings\n",
    "- Language register: {language_style}\n",
    "- Unique constraint: {unique_angle}\n",
    "\n",
    "Output only the example text, no preamble.\"\"\",\n",
    "\n",
    "    # Template 3: Process-Focused\n",
    "    \"\"\"Generate 1 example (2-4 sentences) that shows the PROCESS of {cognitive_action_desc}:\n",
    "\n",
    "Setup: {subject} faces {problem_type} related to {domain}\n",
    "The cognitive action unfolds gradually and visibly.\n",
    "\n",
    "Requirements:\n",
    "- Make the internal process visible\n",
    "- Perspective: {perspective}\n",
    "- Unique angle: {unique_angle}\n",
    "- Language style: {language_style}\n",
    "- Show it taking time, not being instant\n",
    "\n",
    "Output only the example text, no preamble.\"\"\"\n",
    "]\n",
    "\n",
    "# =============================================================================\n",
    "# COGNITIVE ACTION CHAIN TEMPLATES\n",
    "# =============================================================================\n",
    "\n",
    "CHAIN_TEMPLATES = [\n",
    "    # Template: Sequential Chain\n",
    "    \"\"\"Generate 1 example (4-6 sentences) showing this sequence of cognitive actions:\n",
    "\n",
    "Step 1: {cognitive_action_1_desc} triggered by {trigger}\n",
    "Step 2: This leads to {cognitive_action_2_desc}\n",
    "Step 3: Which results in {cognitive_action_3_desc}\n",
    "\n",
    "Context:\n",
    "- Domain: {domain}\n",
    "- Scenario: {context_detail}\n",
    "- Subject: {subject}\n",
    "- Emotional arc: {starting_emotion} → {ending_emotion}\n",
    "\n",
    "Requirements:\n",
    "- Show clear progression between steps\n",
    "- Make causal connections visible\n",
    "- Complexity: {complexity}\n",
    "- Unique constraint: {unique_angle}\n",
    "\n",
    "Output only the example text, no preamble.\"\"\"\n",
    "]\n",
    "\n",
    "# =============================================================================\n",
    "# DIALOGUE TEMPLATES\n",
    "# =============================================================================\n",
    "\n",
    "DIALOGUE_TEMPLATES = [\n",
    "    # Therapy/Coaching Context\n",
    "    \"\"\"Generate a dialogue (3-4 exchanges) showing {cognitive_action_desc} in a therapeutic context:\n",
    "\n",
    "Setting: {therapy_setting}\n",
    "Client issue: {domain} - {context_detail}\n",
    "Cognitive action demonstrated: {cognitive_action_desc}\n",
    "\n",
    "Requirements:\n",
    "- Show the cognitive action emerging through dialogue\n",
    "- Include both therapist and client voices\n",
    "- Emotional tone: {emotional_state}\n",
    "- Make it feel natural and realistic\n",
    "- Unique focus: {unique_angle}\n",
    "\n",
    "Output dialogue format only, no stage directions.\"\"\"\n",
    "]\n",
    "\n",
    "# =============================================================================\n",
    "# THOUGHT-STREAM TEMPLATES\n",
    "# =============================================================================\n",
    "\n",
    "THOUGHT_STREAM_TEMPLATES = [\n",
    "    # Stream of Consciousness\n",
    "    \"\"\"Generate a stream-of-consciousness example (4-6 sentences) showing {cognitive_action_desc}:\n",
    "\n",
    "Initial state: {subject} is {initial_situation} feeling {emotional_state}\n",
    "Domain: {domain}\n",
    "Trigger: {trigger}\n",
    "Cognitive process: {cognitive_action_desc}\n",
    "\n",
    "Requirements:\n",
    "- Show the mind in motion, not just the conclusion\n",
    "- Include false starts, interruptions, tangents\n",
    "- Make it feel like real internal dialogue\n",
    "- Include: {unique_angle}\n",
    "- Complexity: {complexity_level}\n",
    "\n",
    "Output only the thought stream, no framing.\"\"\"\n",
    "]\n",
    "\n",
    "# =============================================================================\n",
    "# NEGATIVE EXAMPLE TEMPLATES\n",
    "# =============================================================================\n",
    "\n",
    "NEGATIVE_TEMPLATES = [\n",
    "    \"\"\"Generate 1 example (2-4 sentences) showing the ABSENCE of {cognitive_action_desc}:\n",
    "\n",
    "Context: {subject} faces {context_detail} in {domain}\n",
    "Trigger present: {trigger}\n",
    "What they DON'T do: {cognitive_action_desc}\n",
    "Instead they: {negative_alternative}\n",
    "\n",
    "Requirements:\n",
    "- Show rigid thinking or missed opportunity\n",
    "- Make it realistic (not caricature)\n",
    "- Emotional state: {emotional_state}\n",
    "- Include: {unique_angle}\n",
    "\n",
    "Output only the example text, no preamble.\"\"\"\n",
    "]\n",
    "\n",
    "# =============================================================================\n",
    "# TEMPLATE PARAMETER GENERATORS\n",
    "# =============================================================================\n",
    "\n",
    "def generate_template_parameters(cognitive_action_key, template_type=\"single\"):\n",
    "    \"\"\"Generate all parameters needed for template formatting\"\"\"\n",
    "    base_params = get_random_selection()\n",
    "    domain = base_params['domain']\n",
    "\n",
    "    params = {\n",
    "        'cognitive_action': cognitive_action_key,\n",
    "        'cognitive_action_desc': COGNITIVE_ACTIONS[cognitive_action_key],\n",
    "        'subject': base_params['subject'],\n",
    "        'domain': domain,\n",
    "        'context_detail': get_context_detail(domain),\n",
    "        'trigger': base_params['trigger'],\n",
    "        'emotional_state': base_params['emotional_state'],\n",
    "        'language_style': base_params['language_style'],\n",
    "        'unique_angle': base_params['unique_angle'],\n",
    "        'complexity_level': base_params['complexity_level'],\n",
    "        'perspective': base_params['perspective']\n",
    "    }\n",
    "\n",
    "    # Add template-specific parameters\n",
    "    if template_type == \"single\":\n",
    "        params.update({\n",
    "            'situation': f\"dealing with {get_context_detail(domain)}\",\n",
    "            'initial_state': f\"initially feeling {random.choice(EMOTIONAL_STATES)}\",\n",
    "            'result_direction': f\"moving toward {random.choice(['clarity', 'acceptance', 'understanding', 'resolution'])}\",\n",
    "            'problem_type': f\"a challenge involving {random.choice(['conflicting values', 'unclear options', 'emotional complexity'])}\"\n",
    "        })\n",
    "\n",
    "    elif template_type == \"chain\":\n",
    "        actions = get_cognitive_action_chains(3)\n",
    "        params.update({\n",
    "            'cognitive_action_1': actions[0],\n",
    "            'cognitive_action_1_desc': COGNITIVE_ACTIONS[actions[0]],\n",
    "            'cognitive_action_2': actions[1],\n",
    "            'cognitive_action_2_desc': COGNITIVE_ACTIONS[actions[1]],\n",
    "            'cognitive_action_3': actions[2],\n",
    "            'cognitive_action_3_desc': COGNITIVE_ACTIONS[actions[2]],\n",
    "            'starting_emotion': random.choice(EMOTIONAL_STATES),\n",
    "            'ending_emotion': random.choice(EMOTIONAL_STATES),\n",
    "            'complexity': params['complexity_level']\n",
    "        })\n",
    "\n",
    "    elif template_type == \"dialogue\":\n",
    "        params.update({\n",
    "            'therapy_setting': random.choice(['therapy session', 'coaching conversation', 'peer support group'])\n",
    "        })\n",
    "\n",
    "    elif template_type == \"thought_stream\":\n",
    "        params.update({\n",
    "            'initial_situation': f\"dealing with {get_context_detail(domain)}\"\n",
    "        })\n",
    "\n",
    "    elif template_type == \"negative\":\n",
    "        params.update({\n",
    "            'negative_alternative': random.choice([\n",
    "                'stick rigidly to their original view',\n",
    "                'dismiss the new information',\n",
    "                'avoid thinking about it',\n",
    "                'become more defensive'\n",
    "            ])\n",
    "        })\n",
    "\n",
    "    return params\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN TEMPLATE SELECTION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def get_random_template(template_type=\"single\"):\n",
    "    \"\"\"Get a random template of specified type\"\"\"\n",
    "    if template_type == \"single\":\n",
    "        return random.choice(SINGLE_ACTION_TEMPLATES)\n",
    "    elif template_type == \"chain\":\n",
    "        return random.choice(CHAIN_TEMPLATES)\n",
    "    elif template_type == \"dialogue\":\n",
    "        return random.choice(DIALOGUE_TEMPLATES)\n",
    "    elif template_type == \"thought_stream\":\n",
    "        return random.choice(THOUGHT_STREAM_TEMPLATES)\n",
    "    elif template_type == \"negative\":\n",
    "        return random.choice(NEGATIVE_TEMPLATES)\n",
    "    else:\n",
    "        return random.choice(SINGLE_ACTION_TEMPLATES)\n",
    "\n",
    "def generate_prompt(cognitive_action_key=None, template_type=\"single\", iteration_number=0):\n",
    "    \"\"\"Generate a complete prompt for the LLM\"\"\"\n",
    "    if cognitive_action_key is None:\n",
    "        cognitive_action_key = random.choice(list(COGNITIVE_ACTIONS.keys()))\n",
    "\n",
    "    template = get_random_template(template_type)\n",
    "    params = generate_template_parameters(cognitive_action_key, template_type)\n",
    "\n",
    "    # Format the template with parameters\n",
    "    try:\n",
    "        prompt = template.format(**params)\n",
    "    except KeyError as e:\n",
    "        # Fallback: add missing parameters\n",
    "        missing_param = str(e).strip(\"'\")\n",
    "        params[missing_param] = f\"[{missing_param}]\"\n",
    "        prompt = template.format(**params)\n",
    "\n",
    "    # Add uniqueness constraint\n",
    "    prompt += f\"\\n\\nExample #{iteration_number + 1}. Make this distinctly different from previous examples.\"\n",
    "\n",
    "    return prompt, params\n",
    "\n",
    "print(\"Prompt templates loaded successfully!\")\n",
    "print(f\"Single action templates: {len(SINGLE_ACTION_TEMPLATES)}\")\n",
    "print(f\"Chain templates: {len(CHAIN_TEMPLATES)}\")\n",
    "print(f\"Dialogue templates: {len(DIALOGUE_TEMPLATES)}\")\n",
    "print(f\"Thought stream templates: {len(THOUGHT_STREAM_TEMPLATES)}\")\n",
    "print(f\"Negative templates: {len(NEGATIVE_TEMPLATES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ollama_setup"
   },
   "source": [
    "## 3. Ollama Setup\n",
    "\n",
    "Choose one of the following options:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ollama_local"
   },
   "source": [
    "### Option A: Local Ollama Installation (Recommended)\n",
    "\n",
    "If you have Ollama running locally, modify the URL below to point to your instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup_ollama_local"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "class OllamaClient:\n",
    "    def __init__(self, base_url=\"http://localhost:11434\"):\n",
    "        self.base_url = base_url\n",
    "        self.session = requests.Session()\n",
    "    \n",
    "    def generate(self, model=\"llama3.2\", prompt=\"\", stream=False):\n",
    "        \"\"\"Generate text using Ollama API\"\"\"\n",
    "        url = f\"{self.base_url}/api/generate\"\n",
    "        data = {\n",
    "            \"model\": model,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": stream\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = self.session.post(url, json=data, timeout=120)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            if stream:\n",
    "                return response.iter_lines()\n",
    "            else:\n",
    "                return response.json()\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error connecting to Ollama: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def list_models(self):\n",
    "        \"\"\"List available models\"\"\"\n",
    "        url = f\"{self.base_url}/api/tags\"\n",
    "        try:\n",
    "            response = self.session.get(url)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error connecting to Ollama: {e}\")\n",
    "            return None\n",
    "\n",
    "# Initialize Ollama client\n",
    "# CHANGE THIS URL TO YOUR OLLAMA INSTANCE\n",
    "ollama = OllamaClient(base_url=\"http://localhost:11434\")\n",
    "\n",
    "# Test connection\n",
    "models = ollama.list_models()\n",
    "if models:\n",
    "    print(\"✅ Connected to Ollama successfully!\")\n",
    "    print(\"Available models:\")\n",
    "    for model in models.get('models', []):\n",
    "        print(f\"  - {model.get('name', 'Unknown')}\")\n",
    "else:\n",
    "    print(\"❌ Could not connect to Ollama. Please check your setup.\")\n",
    "    print(\"Make sure Ollama is running and accessible at the specified URL.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ollama_colab"
   },
   "source": [
    "### Option B: Install Ollama in Colab (Experimental)\n",
    "\n",
    "⚠️ **Note:** This is experimental and may not work reliably in all Colab environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_ollama_colab"
   },
   "outputs": [],
   "source": [
    "# Uncomment and run this cell to install Ollama directly in Colab\n",
    "# This is experimental and may not work in all environments\n",
    "\n",
    "# !curl -fsSL https://ollama.ai/install.sh | sh\n",
    "# \n",
    "# # Start Ollama in background\n",
    "# import subprocess\n",
    "# import time\n",
    "# \n",
    "# # Start Ollama server\n",
    "# ollama_process = subprocess.Popen(['ollama', 'serve'], \n",
    "#                                   stdout=subprocess.PIPE, \n",
    "#                                   stderr=subprocess.PIPE)\n",
    "# \n",
    "# # Wait for server to start\n",
    "# time.sleep(10)\n",
    "# \n",
    "# # Pull a model\n",
    "# !ollama pull llama3.2\n",
    "# \n",
    "# print(\"Ollama installed and model pulled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_generation"
   },
   "source": [
    "## 4. Data Generation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_data_generator"
   },
   "outputs": [],
   "source": [
    "%%writefile data_generator.py\n",
    "\"\"\"\n",
    "Main Data Generation Engine for Cognitive Action Training Data\n",
    "Integrates with Ollama for LLM generation\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "from variable_pools import COGNITIVE_ACTIONS, get_random_selection\n",
    "from prompt_templates import generate_prompt\n",
    "\n",
    "@dataclass\n",
    "class GeneratedExample:\n",
    "    \"\"\"Structure for a generated training example\"\"\"\n",
    "    text: str\n",
    "    primary_cognitive_action: str\n",
    "    secondary_actions: List[str]\n",
    "    domain: str\n",
    "    complexity: str\n",
    "    perspective: str\n",
    "    format_type: str\n",
    "    metadata: Dict[str, Any]\n",
    "\n",
    "class CognitiveDataGenerator:\n",
    "    \"\"\"Main class for generating cognitive action training data\"\"\"\n",
    "\n",
    "    def __init__(self, ollama_client=None):\n",
    "        \"\"\"Initialize the generator with optional Ollama client\"\"\"\n",
    "        self.ollama_client = ollama_client\n",
    "        self.generated_examples = []\n",
    "        self.generation_stats = {\n",
    "            'total_generated': 0,\n",
    "            'by_cognitive_action': {},\n",
    "            'by_domain': {},\n",
    "            'by_complexity': {},\n",
    "            'errors': []\n",
    "        }\n",
    "\n",
    "    def generate_single_example(self,\n",
    "                               cognitive_action: Optional[str] = None,\n",
    "                               template_type: str = \"single\",\n",
    "                               model: str = \"llama3.2\") -> Optional[GeneratedExample]:\n",
    "        \"\"\"Generate a single training example\"\"\"\n",
    "        try:\n",
    "            # Generate prompt\n",
    "            prompt, params = generate_prompt(cognitive_action, template_type,\n",
    "                                           self.generation_stats['total_generated'])\n",
    "\n",
    "            # Generate with Ollama\n",
    "            if self.ollama_client:\n",
    "                response = self.ollama_client.generate(\n",
    "                    model=model,\n",
    "                    prompt=prompt\n",
    "                )\n",
    "                if response:\n",
    "                    generated_text = response['response'].strip()\n",
    "                else:\n",
    "                    generated_text = f\"[Error generating example for {params['cognitive_action']}]\"\n",
    "            else:\n",
    "                # Fallback for testing without Ollama\n",
    "                generated_text = f\"[Generated example for {params['cognitive_action']} in {params['domain']}]\"\n",
    "\n",
    "            # Create example object\n",
    "            example = GeneratedExample(\n",
    "                text=generated_text,\n",
    "                primary_cognitive_action=params['cognitive_action'],\n",
    "                secondary_actions=[],  # Could be extracted with NLP\n",
    "                domain=params['domain'],\n",
    "                complexity=params['complexity_level'],\n",
    "                perspective=params['perspective'],\n",
    "                format_type=template_type,\n",
    "                metadata={\n",
    "                    'subject': params['subject'],\n",
    "                    'emotional_state': params['emotional_state'],\n",
    "                    'language_style': params['language_style'],\n",
    "                    'unique_angle': params['unique_angle'],\n",
    "                    'trigger': params['trigger'],\n",
    "                    'generation_timestamp': time.time(),\n",
    "                    'prompt_used': prompt\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Update statistics\n",
    "            self._update_stats(example)\n",
    "            self.generated_examples.append(example)\n",
    "\n",
    "            return example\n",
    "\n",
    "        except Exception as e:\n",
    "            error_info = {\n",
    "                'error': str(e),\n",
    "                'cognitive_action': cognitive_action,\n",
    "                'template_type': template_type,\n",
    "                'timestamp': time.time()\n",
    "            }\n",
    "            self.generation_stats['errors'].append(error_info)\n",
    "            print(f\"Error generating example: {e}\")\n",
    "            return None\n",
    "\n",
    "    def generate_batch(self,\n",
    "                      batch_size: int = 10,\n",
    "                      cognitive_action: Optional[str] = None,\n",
    "                      template_type: str = \"single\",\n",
    "                      model: str = \"llama3.2\",\n",
    "                      delay: float = 0.5) -> List[GeneratedExample]:\n",
    "        \"\"\"Generate a batch of examples\"\"\"\n",
    "        examples = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            example = self.generate_single_example(cognitive_action, template_type, model)\n",
    "            if example:\n",
    "                examples.append(example)\n",
    "                print(f\"Generated example {i+1}/{batch_size}: {example.primary_cognitive_action}\")\n",
    "\n",
    "            # Delay to avoid overwhelming the API\n",
    "            if delay > 0:\n",
    "                time.sleep(delay)\n",
    "\n",
    "        return examples\n",
    "\n",
    "    def generate_stratified_dataset(self,\n",
    "                                   total_examples: int = 1000,\n",
    "                                   model: str = \"llama3.2\") -> List[GeneratedExample]:\n",
    "        \"\"\"Generate a stratified dataset ensuring coverage across cognitive actions\"\"\"\n",
    "        examples_per_action = total_examples // len(COGNITIVE_ACTIONS)\n",
    "        all_examples = []\n",
    "\n",
    "        for action in COGNITIVE_ACTIONS.keys():\n",
    "            print(f\"Generating {examples_per_action} examples for: {action}\")\n",
    "\n",
    "            # Mix template types for variety\n",
    "            template_types = [\"single\"] * int(examples_per_action * 0.7) + \\\n",
    "                           [\"chain\"] * int(examples_per_action * 0.2) + \\\n",
    "                           [\"dialogue\"] * int(examples_per_action * 0.1)\n",
    "\n",
    "            random.shuffle(template_types)\n",
    "\n",
    "            for i, template_type in enumerate(template_types):\n",
    "                example = self.generate_single_example(action, template_type, model)\n",
    "                if example:\n",
    "                    all_examples.append(example)\n",
    "\n",
    "        # Shuffle final dataset\n",
    "        random.shuffle(all_examples)\n",
    "        return all_examples\n",
    "\n",
    "    def _update_stats(self, example: GeneratedExample):\n",
    "        \"\"\"Update generation statistics\"\"\"\n",
    "        self.generation_stats['total_generated'] += 1\n",
    "\n",
    "        # Update by cognitive action\n",
    "        action = example.primary_cognitive_action\n",
    "        if action not in self.generation_stats['by_cognitive_action']:\n",
    "            self.generation_stats['by_cognitive_action'][action] = 0\n",
    "        self.generation_stats['by_cognitive_action'][action] += 1\n",
    "\n",
    "        # Update by domain\n",
    "        domain = example.domain\n",
    "        if domain not in self.generation_stats['by_domain']:\n",
    "            self.generation_stats['by_domain'][domain] = 0\n",
    "        self.generation_stats['by_domain'][domain] += 1\n",
    "\n",
    "        # Update by complexity\n",
    "        complexity = example.complexity\n",
    "        if complexity not in self.generation_stats['by_complexity']:\n",
    "            self.generation_stats['by_complexity'][complexity] = 0\n",
    "        self.generation_stats['by_complexity'][complexity] += 1\n",
    "\n",
    "    def export_dataset(self, filepath: str, format: str = \"jsonl\"):\n",
    "        \"\"\"Export generated dataset to file\"\"\"\n",
    "        if format == \"jsonl\":\n",
    "            with open(filepath, 'w') as f:\n",
    "                for example in self.generated_examples:\n",
    "                    json_obj = {\n",
    "                        'text': example.text,\n",
    "                        'primary_cognitive_action': example.primary_cognitive_action,\n",
    "                        'secondary_actions': example.secondary_actions,\n",
    "                        'domain': example.domain,\n",
    "                        'complexity': example.complexity,\n",
    "                        'perspective': example.perspective,\n",
    "                        'format_type': example.format_type,\n",
    "                        'metadata': example.metadata\n",
    "                    }\n",
    "                    f.write(json.dumps(json_obj) + '\\n')\n",
    "\n",
    "        elif format == \"json\":\n",
    "            with open(filepath, 'w') as f:\n",
    "                dataset = [\n",
    "                    {\n",
    "                        'text': example.text,\n",
    "                        'primary_cognitive_action': example.primary_cognitive_action,\n",
    "                        'secondary_actions': example.secondary_actions,\n",
    "                        'domain': example.domain,\n",
    "                        'complexity': example.complexity,\n",
    "                        'perspective': example.perspective,\n",
    "                        'format_type': example.format_type,\n",
    "                        'metadata': example.metadata\n",
    "                    }\n",
    "                    for example in self.generated_examples\n",
    "                ]\n",
    "                json.dump(dataset, f, indent=2)\n",
    "\n",
    "        print(f\"Exported {len(self.generated_examples)} examples to {filepath}\")\n",
    "\n",
    "    def get_statistics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get generation statistics\"\"\"\n",
    "        return self.generation_stats\n",
    "\n",
    "    def print_statistics(self):\n",
    "        \"\"\"Print formatted statistics\"\"\"\n",
    "        stats = self.generation_stats\n",
    "        print(f\"\\nGeneration Statistics:\")\n",
    "        print(f\"Total examples generated: {stats['total_generated']}\")\n",
    "        print(f\"Errors encountered: {len(stats['errors'])}\")\n",
    "\n",
    "        print(f\"\\nBy Cognitive Action:\")\n",
    "        for action, count in sorted(stats['by_cognitive_action'].items()):\n",
    "            print(f\"  {action}: {count}\")\n",
    "\n",
    "        print(f\"\\nBy Domain:\")\n",
    "        for domain, count in sorted(stats['by_domain'].items()):\n",
    "            print(f\"  {domain}: {count}\")\n",
    "\n",
    "        print(f\"\\nBy Complexity:\")\n",
    "        for complexity, count in sorted(stats['by_complexity'].items()):\n",
    "            print(f\"  {complexity}: {count}\")\n",
    "\n",
    "print(\"Data generator loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import_modules"
   },
   "outputs": [],
   "source": [
    "# Import the modules we just created\n",
    "from variable_pools import *\n",
    "from prompt_templates import *\n",
    "from data_generator import *\n",
    "\n",
    "print(\"All modules imported successfully!\")\n",
    "print(f\"Ready to generate data with {len(COGNITIVE_ACTIONS)} cognitive actions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test_generation"
   },
   "source": [
    "## 5. Test the System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_prompt_generation"
   },
   "outputs": [],
   "source": [
    "# Test prompt generation without LLM\n",
    "print(\"Testing prompt generation...\\n\")\n",
    "\n",
    "# Generate a few sample prompts\n",
    "for i in range(3):\n",
    "    prompt, params = generate_prompt(template_type=\"single\", iteration_number=i)\n",
    "    print(f\"=== PROMPT {i+1} ===\")\n",
    "    print(f\"Cognitive Action: {params['cognitive_action']}\")\n",
    "    print(f\"Domain: {params['domain']}\")\n",
    "    print(f\"Subject: {params['subject']}\")\n",
    "    print()\n",
    "    print(prompt)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_with_ollama"
   },
   "outputs": [],
   "source": [
    "# Test with Ollama (if connected)\n",
    "generator = CognitiveDataGenerator(ollama_client=ollama)\n",
    "\n",
    "print(\"Testing single example generation...\")\n",
    "\n",
    "# Generate a single example\n",
    "example = generator.generate_single_example(\n",
    "    cognitive_action=\"reconsidering\",\n",
    "    template_type=\"single\",\n",
    "    model=\"llama3.2\"  # Change this to your available model\n",
    ")\n",
    "\n",
    "if example:\n",
    "    print(\"\\n=== GENERATED EXAMPLE ===\")\n",
    "    print(f\"Cognitive Action: {example.primary_cognitive_action}\")\n",
    "    print(f\"Domain: {example.domain}\")\n",
    "    print(f\"Complexity: {example.complexity}\")\n",
    "    print(f\"Format: {example.format_type}\")\n",
    "    print()\n",
    "    print(\"Generated Text:\")\n",
    "    print(example.text)\n",
    "    print()\n",
    "    print(\"Metadata:\")\n",
    "    for key, value in example.metadata.items():\n",
    "        if key != 'prompt_used':  # Skip the long prompt\n",
    "            print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(\"Failed to generate example. Check Ollama connection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch_generation"
   },
   "source": [
    "## 6. Batch Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "small_batch_test"
   },
   "outputs": [],
   "source": [
    "# Generate a small batch for testing\n",
    "print(\"Generating small test batch...\")\n",
    "\n",
    "test_examples = generator.generate_batch(\n",
    "    batch_size=5,\n",
    "    cognitive_action=None,  # Random actions\n",
    "    template_type=\"single\",\n",
    "    model=\"llama3.2\",\n",
    "    delay=1.0  # 1 second delay between generations\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {len(test_examples)} examples\")\n",
    "\n",
    "# Show a few examples\n",
    "for i, example in enumerate(test_examples[:3]):\n",
    "    print(f\"\\n=== EXAMPLE {i+1} ===\")\n",
    "    print(f\"Action: {example.primary_cognitive_action}\")\n",
    "    print(f\"Domain: {example.domain}\")\n",
    "    print(f\"Text: {example.text[:200]}...\")\n",
    "\n",
    "# Show statistics\n",
    "generator.print_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stratified_generation"
   },
   "outputs": [],
   "source": [
    "# Generate stratified dataset (smaller for testing)\n",
    "print(\"Generating stratified test dataset...\")\n",
    "\n",
    "# Create new generator for clean stats\n",
    "stratified_generator = CognitiveDataGenerator(ollama_client=ollama)\n",
    "\n",
    "stratified_examples = stratified_generator.generate_stratified_dataset(\n",
    "    total_examples=100,  # Start small for testing\n",
    "    model=\"llama3.2\"\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {len(stratified_examples)} stratified examples\")\n",
    "stratified_generator.print_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_analysis"
   },
   "source": [
    "## 7. Data Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "analyze_data"
   },
   "outputs": [],
   "source": [
    "# Convert to DataFrame for analysis\n",
    "data = []\n",
    "for example in stratified_generator.generated_examples:\n",
    "    data.append({\n",
    "        'text': example.text,\n",
    "        'cognitive_action': example.primary_cognitive_action,\n",
    "        'domain': example.domain,\n",
    "        'complexity': example.complexity,\n",
    "        'format_type': example.format_type,\n",
    "        'text_length': len(example.text),\n",
    "        'word_count': len(example.text.split()),\n",
    "        'subject': example.metadata.get('subject', ''),\n",
    "        'emotional_state': example.metadata.get('emotional_state', '')\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize_data"
   },
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Distribution of cognitive actions\n",
    "plt.subplot(2, 3, 1)\n",
    "cognitive_action_counts = df['cognitive_action'].value_counts()\n",
    "plt.bar(range(len(cognitive_action_counts)), cognitive_action_counts.values)\n",
    "plt.xticks(range(len(cognitive_action_counts)), cognitive_action_counts.index, rotation=45, ha='right')\n",
    "plt.title('Distribution of Cognitive Actions')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Distribution of domains\n",
    "plt.subplot(2, 3, 2)\n",
    "domain_counts = df['domain'].value_counts()[:10]  # Top 10\n",
    "plt.bar(range(len(domain_counts)), domain_counts.values)\n",
    "plt.xticks(range(len(domain_counts)), domain_counts.index, rotation=45, ha='right')\n",
    "plt.title('Top 10 Domains')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Distribution of complexity levels\n",
    "plt.subplot(2, 3, 3)\n",
    "complexity_counts = df['complexity'].value_counts()\n",
    "plt.pie(complexity_counts.values, labels=complexity_counts.index, autopct='%1.1f%%')\n",
    "plt.title('Complexity Distribution')\n",
    "\n",
    "# Text length distribution\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.hist(df['text_length'], bins=20, edgecolor='black')\n",
    "plt.title('Text Length Distribution')\n",
    "plt.xlabel('Characters')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Word count distribution\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.hist(df['word_count'], bins=20, edgecolor='black')\n",
    "plt.title('Word Count Distribution')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Format type distribution\n",
    "plt.subplot(2, 3, 6)\n",
    "format_counts = df['format_type'].value_counts()\n",
    "plt.pie(format_counts.values, labels=format_counts.index, autopct='%1.1f%%')\n",
    "plt.title('Format Type Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show some sample texts by cognitive action\n",
    "print(\"\\n=== SAMPLE TEXTS BY COGNITIVE ACTION ===\")\n",
    "for action in df['cognitive_action'].unique()[:5]:  # First 5 actions\n",
    "    sample = df[df['cognitive_action'] == action]['text'].iloc[0]\n",
    "    print(f\"\\n{action.upper()}:\")\n",
    "    print(f\"  {sample[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export_data"
   },
   "source": [
    "## 8. Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_datasets"
   },
   "outputs": [],
   "source": [
    "# Export the generated dataset\n",
    "timestamp = int(time.time())\n",
    "\n",
    "# Export as JSONL (recommended for large datasets)\n",
    "jsonl_filename = f\"cognitive_actions_dataset_{timestamp}.jsonl\"\n",
    "stratified_generator.export_dataset(jsonl_filename, format=\"jsonl\")\n",
    "\n",
    "# Export as JSON (for smaller datasets)\n",
    "json_filename = f\"cognitive_actions_dataset_{timestamp}.json\"\n",
    "stratified_generator.export_dataset(json_filename, format=\"json\")\n",
    "\n",
    "# Export as CSV for analysis\n",
    "csv_filename = f\"cognitive_actions_analysis_{timestamp}.csv\"\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"\\nDataset exported:\")\n",
    "print(f\"  JSONL: {jsonl_filename}\")\n",
    "print(f\"  JSON: {json_filename}\")\n",
    "print(f\"  CSV: {csv_filename}\")\n",
    "\n",
    "# Show file sizes\n",
    "import os\n",
    "for filename in [jsonl_filename, json_filename, csv_filename]:\n",
    "    if os.path.exists(filename):\n",
    "        size = os.path.getsize(filename)\n",
    "        print(f\"  {filename}: {size:,} bytes ({size/1024:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "large_scale_generation"
   },
   "source": [
    "## 9. Large Scale Generation\n",
    "\n",
    "⚠️ **Warning:** Large scale generation can take hours and consume significant computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "configure_large_scale"
   },
   "outputs": [],
   "source": [
    "# Configuration for large-scale generation\n",
    "LARGE_SCALE_CONFIG = {\n",
    "    'phase1_round1': 10000,  # Core cognitive actions\n",
    "    'phase1_round2': 5000,   # Action combinations  \n",
    "    'phase2': 10000,         # Domain variations\n",
    "    'phase3': 10000,         # Complexity variations\n",
    "    'phase4': 2000,          # Negative examples\n",
    "    'phase5': 2000,          # Dialogue format\n",
    "    'phase6': 1000,          # Thought-stream format\n",
    "    'model': 'llama3.2',\n",
    "    'delay': 0.1,            # Delay between generations (seconds)\n",
    "    'checkpoint_interval': 100  # Save progress every N examples\n",
    "}\n",
    "\n",
    "print(\"Large scale configuration:\")\n",
    "total_target = sum(v for k, v in LARGE_SCALE_CONFIG.items() if k.startswith('phase'))\n",
    "print(f\"Total target examples: {total_target:,}\")\n",
    "print(f\"Estimated time (with {LARGE_SCALE_CONFIG['delay']}s delay): {total_target * LARGE_SCALE_CONFIG['delay'] / 3600:.1f} hours\")\n",
    "\n",
    "for phase, count in LARGE_SCALE_CONFIG.items():\n",
    "    if phase.startswith('phase'):\n",
    "        print(f\"  {phase}: {count:,} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_large_scale"
   },
   "outputs": [],
   "source": [
    "# Uncomment and run this cell for large-scale generation\n",
    "# WARNING: This will take a very long time!\n",
    "\n",
    "# def run_large_scale_generation():\n",
    "#     \"\"\"Run the complete large-scale generation pipeline\"\"\"\n",
    "#     \n",
    "#     large_generator = CognitiveDataGenerator(ollama_client=ollama)\n",
    "#     \n",
    "#     phases = [\n",
    "#         ('phase1_round1', 'single', LARGE_SCALE_CONFIG['phase1_round1']),\n",
    "#         ('phase1_round2', 'chain', LARGE_SCALE_CONFIG['phase1_round2']),\n",
    "#         ('phase2', 'single', LARGE_SCALE_CONFIG['phase2']),\n",
    "#         ('phase3', 'single', LARGE_SCALE_CONFIG['phase3']),\n",
    "#         ('phase4', 'negative', LARGE_SCALE_CONFIG['phase4']),\n",
    "#         ('phase5', 'dialogue', LARGE_SCALE_CONFIG['phase5']),\n",
    "#         ('phase6', 'thought_stream', LARGE_SCALE_CONFIG['phase6'])\n",
    "#     ]\n",
    "#     \n",
    "#     for phase_name, template_type, target_count in phases:\n",
    "#         print(f\"\\n🚀 Starting {phase_name}: {target_count:,} examples\")\n",
    "#         print(f\"Template type: {template_type}\")\n",
    "#         \n",
    "#         phase_examples = large_generator.generate_batch(\n",
    "#             batch_size=target_count,\n",
    "#             template_type=template_type,\n",
    "#             model=LARGE_SCALE_CONFIG['model'],\n",
    "#             delay=LARGE_SCALE_CONFIG['delay']\n",
    "#         )\n",
    "#         \n",
    "#         print(f\"✅ Completed {phase_name}: {len(phase_examples):,} examples\")\n",
    "#         \n",
    "#         # Checkpoint save\n",
    "#         checkpoint_filename = f\"checkpoint_{phase_name}_{int(time.time())}.jsonl\"\n",
    "#         large_generator.export_dataset(checkpoint_filename, format=\"jsonl\")\n",
    "#         print(f\"💾 Checkpoint saved: {checkpoint_filename}\")\n",
    "#         \n",
    "#         # Print progress statistics\n",
    "#         large_generator.print_statistics()\n",
    "#     \n",
    "#     # Final export\n",
    "#     final_timestamp = int(time.time())\n",
    "#     final_filename = f\"cognitive_actions_complete_dataset_{final_timestamp}.jsonl\"\n",
    "#     large_generator.export_dataset(final_filename, format=\"jsonl\")\n",
    "#     \n",
    "#     print(f\"\\n🎉 COMPLETE! Generated {len(large_generator.generated_examples):,} examples\")\n",
    "#     print(f\"📁 Final dataset: {final_filename}\")\n",
    "#     \n",
    "#     return large_generator\n",
    "\n",
    "# # Uncomment the line below to start large-scale generation\n",
    "# # large_generator = run_large_scale_generation()\n",
    "\n",
    "print(\"Large-scale generation function defined.\")\n",
    "print(\"Uncomment the last line and run this cell to start large-scale generation.\")\n",
    "print(\"⚠️  Make sure you have sufficient time and resources before starting!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quality_control"
   },
   "source": [
    "## 10. Quality Control and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quality_checks"
   },
   "outputs": [],
   "source": [
    "def quality_control_analysis(examples):\n",
    "    \"\"\"Perform quality control analysis on generated examples\"\"\"\n",
    "    \n",
    "    print(\"=== QUALITY CONTROL ANALYSIS ===\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    total_examples = len(examples)\n",
    "    print(f\"Total examples analyzed: {total_examples:,}\")\n",
    "    \n",
    "    # Text length analysis\n",
    "    text_lengths = [len(ex.text) for ex in examples]\n",
    "    word_counts = [len(ex.text.split()) for ex in examples]\n",
    "    \n",
    "    print(f\"\\nText Length Statistics:\")\n",
    "    print(f\"  Average characters: {np.mean(text_lengths):.1f}\")\n",
    "    print(f\"  Average words: {np.mean(word_counts):.1f}\")\n",
    "    print(f\"  Min/Max characters: {min(text_lengths)} / {max(text_lengths)}\")\n",
    "    print(f\"  Min/Max words: {min(word_counts)} / {max(word_counts)}\")\n",
    "    \n",
    "    # Coverage analysis\n",
    "    cognitive_actions = set(ex.primary_cognitive_action for ex in examples)\n",
    "    domains = set(ex.domain for ex in examples)\n",
    "    \n",
    "    print(f\"\\nCoverage Statistics:\")\n",
    "    print(f\"  Cognitive actions covered: {len(cognitive_actions)}/{len(COGNITIVE_ACTIONS)} ({len(cognitive_actions)/len(COGNITIVE_ACTIONS)*100:.1f}%)\")\n",
    "    print(f\"  Domains covered: {len(domains)}/{len(DOMAINS)} ({len(domains)/len(DOMAINS)*100:.1f}%)\")\n",
    "    \n",
    "    # Quality indicators\n",
    "    print(f\"\\nQuality Indicators:\")\n",
    "    \n",
    "    # Check for very short examples\n",
    "    very_short = sum(1 for length in text_lengths if length < 50)\n",
    "    print(f\"  Very short examples (<50 chars): {very_short} ({very_short/total_examples*100:.1f}%)\")\n",
    "    \n",
    "    # Check for very long examples\n",
    "    very_long = sum(1 for length in text_lengths if length > 1000)\n",
    "    print(f\"  Very long examples (>1000 chars): {very_long} ({very_long/total_examples*100:.1f}%)\")\n",
    "    \n",
    "    # Check for examples that might contain prompt artifacts\n",
    "    prompt_artifacts = sum(1 for ex in examples if any(word in ex.text.lower() for word in \n",
    "                          ['generate', 'example', 'sentence', 'requirement', 'output']))\n",
    "    print(f\"  Potential prompt artifacts: {prompt_artifacts} ({prompt_artifacts/total_examples*100:.1f}%)\")\n",
    "    \n",
    "    # Diversity check - look for repeated phrases\n",
    "    all_texts = [ex.text for ex in examples]\n",
    "    unique_texts = set(all_texts)\n",
    "    print(f\"  Unique texts: {len(unique_texts)}/{total_examples} ({len(unique_texts)/total_examples*100:.1f}%)\")\n",
    "    \n",
    "    return {\n",
    "        'total_examples': total_examples,\n",
    "        'avg_length': np.mean(text_lengths),\n",
    "        'avg_words': np.mean(word_counts),\n",
    "        'cognitive_actions_covered': len(cognitive_actions),\n",
    "        'domains_covered': len(domains),\n",
    "        'very_short_pct': very_short/total_examples*100,\n",
    "        'very_long_pct': very_long/total_examples*100,\n",
    "        'prompt_artifacts_pct': prompt_artifacts/total_examples*100,\n",
    "        'uniqueness_pct': len(unique_texts)/total_examples*100\n",
    "    }\n",
    "\n",
    "# Run quality control on current examples\n",
    "if stratified_generator.generated_examples:\n",
    "    qc_results = quality_control_analysis(stratified_generator.generated_examples)\n",
    "else:\n",
    "    print(\"No examples to analyze. Generate some examples first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sample_review"
   },
   "outputs": [],
   "source": [
    "# Manual review of sample examples\n",
    "def review_samples(examples, n_samples=5):\n",
    "    \"\"\"Review a random sample of examples for quality\"\"\"\n",
    "    \n",
    "    if not examples:\n",
    "        print(\"No examples to review.\")\n",
    "        return\n",
    "    \n",
    "    print(\"=== MANUAL QUALITY REVIEW ===\")\n",
    "    print(f\"Reviewing {min(n_samples, len(examples))} random examples:\\n\")\n",
    "    \n",
    "    sample_examples = random.sample(examples, min(n_samples, len(examples)))\n",
    "    \n",
    "    for i, example in enumerate(sample_examples, 1):\n",
    "        print(f\"--- EXAMPLE {i} ---\")\n",
    "        print(f\"Cognitive Action: {example.primary_cognitive_action}\")\n",
    "        print(f\"Domain: {example.domain}\")\n",
    "        print(f\"Complexity: {example.complexity}\")\n",
    "        print(f\"Format: {example.format_type}\")\n",
    "        print(f\"Length: {len(example.text)} chars, {len(example.text.split())} words\")\n",
    "        print()\n",
    "        print(\"Text:\")\n",
    "        print(f\"\\\"{example.text}\\\"\")\n",
    "        print()\n",
    "        print(\"Subject:\", example.metadata.get('subject', 'N/A'))\n",
    "        print(\"Emotional State:\", example.metadata.get('emotional_state', 'N/A'))\n",
    "        print(\"Unique Angle:\", example.metadata.get('unique_angle', 'N/A'))\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Review samples\n",
    "if stratified_generator.generated_examples:\n",
    "    review_samples(stratified_generator.generated_examples, n_samples=3)\n",
    "else:\n",
    "    print(\"No examples to review. Generate some examples first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion"
   },
   "source": [
    "## 🎉 Conclusion\n",
    "\n",
    "You now have a complete cognitive action data generation system!\n",
    "\n",
    "### What You've Built:\n",
    "- **Scientific Foundation**: Based on established taxonomies from cognitive psychology\n",
    "- **Flexible Architecture**: Modular system with variable pools and templates\n",
    "- **Scalable Generation**: Can generate from small batches to 100,000+ examples\n",
    "- **Quality Control**: Built-in analysis and validation tools\n",
    "- **Multiple Formats**: Support for various example types (single actions, chains, dialogues, thought streams)\n",
    "\n",
    "### Next Steps:\n",
    "1. **Scale Up**: Use the large-scale generation for your full dataset\n",
    "2. **Fine-tune**: Adjust templates and variables based on your specific needs\n",
    "3. **Validate**: Run quality control on larger datasets\n",
    "4. **Train Models**: Use the generated data to train your cognitive action recognition models\n",
    "\n",
    "### Tips for Production Use:\n",
    "- Monitor generation quality regularly\n",
    "- Save checkpoints during long generation runs\n",
    "- Experiment with different Ollama models for variety\n",
    "- Consider post-processing for consistency\n",
    "\n",
    "**Happy data generating! 🚀**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}