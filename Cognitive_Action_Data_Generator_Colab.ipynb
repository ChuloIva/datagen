{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cognitive Action Training Data Generator (Google Colab)\n",
    "\n",
    "Generate 7,000 high-quality stratified training examples for cognitive action recognition.\n",
    "\n",
    "**Based on Scientific Taxonomies:**\n",
    "- Bloom's Taxonomy (cognitive processes)\n",
    "- Guilford's Structure of Intellect\n",
    "- Krathwohl's Affective Domain\n",
    "- Gross's Emotion Regulation Model\n",
    "\n",
    "**Features:**\n",
    "- ‚ö° Async parallel processing (16x speedup)\n",
    "- üéØ Stratified sampling across 45 cognitive actions\n",
    "- üíæ Auto-checkpointing every 100 examples to Google Drive\n",
    "- üöÄ Optimized for 40GB VRAM (Google Colab A100)\n",
    "\n",
    "**Estimated Time:** ~3.7 hours for 7,000 examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q requests pandas numpy tqdm matplotlib seaborn aiohttp nest-asyncio\n",
    "\n",
    "# Clone the repository\n",
    "import os\n",
    "if not os.path.exists('datagen'):\n",
    "    print(\"üì• Cloning datagen repository...\")\n",
    "    !git clone https://github.com/ChuloIva/datagen.git\n",
    "    print(\"‚úÖ Repository cloned successfully!\")\n",
    "else:\n",
    "    print(\"‚úÖ Repository already exists\")\n",
    "\n",
    "# Import libraries\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Apply nest_asyncio for Jupyter/Colab compatibility\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Set random seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Install & Configure Ollama\n",
    "\n",
    "This cell installs Ollama and configures it for maximum parallel processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ollama\n",
    "!curl -fsSL https://ollama.ai/install.sh | sh\n",
    "\n",
    "# Stop any existing Ollama processes\n",
    "print(\"üõë Stopping any existing Ollama processes...\")\n",
    "subprocess.run(['pkill', '-9', 'ollama'], stderr=subprocess.DEVNULL)\n",
    "time.sleep(2)\n",
    "\n",
    "# Set environment variables for high parallelism\n",
    "print(\"\\n‚öôÔ∏è  Configuring Ollama for maximum GPU utilization...\")\n",
    "os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
    "os.environ['OLLAMA_ORIGINS'] = '*'\n",
    "os.environ['OLLAMA_NUM_PARALLEL'] = '16'  # 16 parallel context buffers\n",
    "os.environ['OLLAMA_MAX_QUEUE'] = '512'\n",
    "os.environ['OLLAMA_MAX_LOADED_MODELS'] = '1'\n",
    "os.environ['LD_LIBRARY_PATH'] = '/usr/lib64-nvidia'\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  OLLAMA_NUM_PARALLEL: 16 (16 concurrent requests)\")\n",
    "print(f\"  OLLAMA_MAX_QUEUE: 512\")\n",
    "\n",
    "# Start Ollama server\n",
    "print(\"\\nüöÄ Starting Ollama server...\")\n",
    "subprocess.Popen(['ollama', 'serve'], \n",
    "                 env=os.environ.copy(),\n",
    "                 stdout=subprocess.DEVNULL,\n",
    "                 stderr=subprocess.DEVNULL)\n",
    "\n",
    "print(\"‚è≥ Waiting for Ollama to start...\")\n",
    "time.sleep(10)\n",
    "\n",
    "# Verify Ollama is running\n",
    "try:\n",
    "    response = requests.get('http://localhost:11434/api/tags', timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        print(\"‚úÖ Ollama is running!\")\n",
    "    else:\n",
    "        print(\"‚ùå Ollama error\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Connection error: {e}\")\n",
    "\n",
    "print(\"\\nüí° VRAM Usage: Model loads at ~18GB. During generation, VRAM will increase to ~38GB with 16 parallel requests.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Pull the Model\n",
    "\n",
    "Download gemma3:27b model (this may take several minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üì• Pulling gemma3:27b model (this may take 5-10 minutes)...\")\n",
    "!ollama pull gemma3:27b\n",
    "print(\"\\n‚úÖ Model ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Load Data Generation Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add datagen to Python path\n",
    "import sys\n",
    "datagen_dir = os.path.abspath('datagen')\n",
    "if datagen_dir not in sys.path:\n",
    "    sys.path.insert(0, datagen_dir)\n",
    "\n",
    "# Import modules\n",
    "from variable_pools import COGNITIVE_ACTIONS\n",
    "from prompt_templates import *\n",
    "from data_generator import CognitiveDataGenerator\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(COGNITIVE_ACTIONS)} cognitive actions\")\n",
    "print(f\"‚úÖ Data generator ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Create Ollama Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OllamaClient:\n",
    "    def __init__(self, base_url=\"http://localhost:11434\"):\n",
    "        self.base_url = base_url\n",
    "        self.session = requests.Session()\n",
    "    \n",
    "    def generate(self, model=\"gemma3:27b\", prompt=\"\", stream=False):\n",
    "        url = f\"{self.base_url}/api/generate\"\n",
    "        data = {\"model\": model, \"prompt\": prompt, \"stream\": stream}\n",
    "        try:\n",
    "            response = self.session.post(url, json=data, timeout=120)\n",
    "            response.raise_for_status()\n",
    "            return response.json() if not stream else response.iter_lines()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return None\n",
    "\n",
    "# Initialize client\n",
    "ollama = OllamaClient()\n",
    "print(\"‚úÖ Ollama client ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Mount Google Drive (for checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create checkpoint directory\n",
    "checkpoint_dir = '/content/drive/MyDrive/cognitive_data_checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "print(f\"‚úÖ Checkpoints will be saved to: {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'total_examples': 7000,\n",
    "    'model': 'gemma3:27b',\n",
    "    'max_parallel': 16,\n",
    "    'checkpoint_interval': 100,\n",
    "    'checkpoint_dir': checkpoint_dir\n",
    "}\n",
    "\n",
    "examples_per_action = CONFIG['total_examples'] // len(COGNITIVE_ACTIONS)\n",
    "estimated_hours = CONFIG['total_examples'] / CONFIG['max_parallel'] * 30 / 3600\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"GENERATION CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total examples: {CONFIG['total_examples']:,}\")\n",
    "print(f\"Cognitive actions: {len(COGNITIVE_ACTIONS)}\")\n",
    "print(f\"Examples per action: ~{examples_per_action}\")\n",
    "print(f\"Parallel requests: {CONFIG['max_parallel']}\")\n",
    "print(f\"Checkpoint every: {CONFIG['checkpoint_interval']} examples\")\n",
    "print(f\"\\nEstimated time: {estimated_hours:.1f} hours ({estimated_hours*60:.0f} minutes)\")\n",
    "print(\"\\nTemplate mix: 70% single, 20% chain, 5% dialogue, 5% thought-stream\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Generate 7,000 Examples (Stratified)\n",
    "\n",
    "‚ö†Ô∏è **This will take ~3.7 hours. Checkpoints are saved every 100 examples.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generator\n",
    "generator = CognitiveDataGenerator(\n",
    "    ollama_client=ollama,\n",
    "    max_parallel=CONFIG['max_parallel']\n",
    ")\n",
    "\n",
    "total_target = CONFIG['total_examples']\n",
    "examples_per_action = total_target // len(COGNITIVE_ACTIONS)\n",
    "checkpoint_interval = CONFIG['checkpoint_interval']\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üöÄ STARTING STRATIFIED GENERATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Target: {total_target:,} examples\")\n",
    "print(f\"Actions: {len(COGNITIVE_ACTIONS)}\")\n",
    "print(f\"Per action: {examples_per_action}\")\n",
    "print(f\"Parallel: {CONFIG['max_parallel']}\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "checkpoint_counter = 0\n",
    "\n",
    "# Generate for each cognitive action\n",
    "for action_idx, action in enumerate(COGNITIVE_ACTIONS.keys(), 1):\n",
    "    print(f\"\\n[{action_idx}/{len(COGNITIVE_ACTIONS)}] {action}\")\n",
    "    \n",
    "    # Mix template types\n",
    "    template_dist = (\n",
    "        [\"single\"] * int(examples_per_action * 0.7) +\n",
    "        [\"chain\"] * int(examples_per_action * 0.2) +\n",
    "        [\"dialogue\"] * int(examples_per_action * 0.05) +\n",
    "        [\"thought_stream\"] * int(examples_per_action * 0.05)\n",
    "    )\n",
    "    while len(template_dist) < examples_per_action:\n",
    "        template_dist.append(\"single\")\n",
    "    template_dist = template_dist[:examples_per_action]\n",
    "    random.shuffle(template_dist)\n",
    "    \n",
    "    # Generate in checkpoint batches\n",
    "    num_batches = (examples_per_action + checkpoint_interval - 1) // checkpoint_interval\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * checkpoint_interval\n",
    "        end_idx = min(start_idx + checkpoint_interval, examples_per_action)\n",
    "        batch_templates = template_dist[start_idx:end_idx]\n",
    "        \n",
    "        # Count templates\n",
    "        template_counts = {}\n",
    "        for t in batch_templates:\n",
    "            template_counts[t] = template_counts.get(t, 0) + 1\n",
    "        \n",
    "        # Generate\n",
    "        batch_examples = []\n",
    "        for template_type, count in template_counts.items():\n",
    "            print(f\"  [{batch_idx+1}/{num_batches}] {count} {template_type}...\")\n",
    "            examples = generator.generate_batch(\n",
    "                batch_size=count,\n",
    "                cognitive_action=action,\n",
    "                template_type=template_type,\n",
    "                model=CONFIG['model']\n",
    "            )\n",
    "            batch_examples.extend(examples)\n",
    "        \n",
    "        # Save checkpoint\n",
    "        checkpoint_counter += 1\n",
    "        checkpoint_file = os.path.join(\n",
    "            CONFIG['checkpoint_dir'],\n",
    "            f\"checkpoint_{checkpoint_counter:04d}_{action}_{int(time.time())}.jsonl\"\n",
    "        )\n",
    "        \n",
    "        with open(checkpoint_file, 'w') as f:\n",
    "            for ex in batch_examples:\n",
    "                json_obj = {\n",
    "                    'text': ex.text,\n",
    "                    'primary_cognitive_action': ex.primary_cognitive_action,\n",
    "                    'secondary_actions': ex.secondary_actions,\n",
    "                    'domain': ex.domain,\n",
    "                    'complexity': ex.complexity,\n",
    "                    'perspective': ex.perspective,\n",
    "                    'format_type': ex.format_type,\n",
    "                    'metadata': ex.metadata\n",
    "                }\n",
    "                f.write(json.dumps(json_obj) + '\\n')\n",
    "        \n",
    "        progress = len(generator.generated_examples) / total_target * 100\n",
    "        print(f\"  ‚úì Checkpoint {checkpoint_counter} | Progress: {len(generator.generated_examples):,}/{total_target:,} ({progress:.1f}%)\")\n",
    "\n",
    "# Final export\n",
    "elapsed = time.time() - start_time\n",
    "final_file = os.path.join(\n",
    "    CONFIG['checkpoint_dir'],\n",
    "    f\"cognitive_actions_7k_final_{int(time.time())}.jsonl\"\n",
    ")\n",
    "generator.export_dataset(final_file, format=\"jsonl\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ GENERATION COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Examples generated: {len(generator.generated_examples):,}\")\n",
    "print(f\"Time elapsed: {elapsed/3600:.2f} hours ({elapsed/60:.1f} minutes)\")\n",
    "print(f\"Checkpoints saved: {checkpoint_counter}\")\n",
    "print(f\"Final dataset: {final_file}\")\n",
    "print(f\"Errors: {len(generator.generation_stats['errors'])}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Print statistics\n",
    "generator.print_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Download Final Dataset\n",
    "\n",
    "Your data is saved in Google Drive, but you can also download it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Find the final file\n",
    "import glob\n",
    "final_files = glob.glob(os.path.join(CONFIG['checkpoint_dir'], \"cognitive_actions_7k_final_*.jsonl\"))\n",
    "if final_files:\n",
    "    latest_file = max(final_files, key=os.path.getctime)\n",
    "    print(f\"Downloading: {os.path.basename(latest_file)}\")\n",
    "    files.download(latest_file)\n",
    "    print(\"‚úÖ Download started!\")\n",
    "else:\n",
    "    print(\"‚ùå No final file found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Done!\n",
    "\n",
    "You now have 7,000 stratified cognitive action examples saved to:\n",
    "- **Google Drive**: `/content/drive/MyDrive/cognitive_data_checkpoints/`\n",
    "- **Checkpoints**: One file per 100 examples (for recovery)\n",
    "- **Final dataset**: `cognitive_actions_7k_final_[timestamp].jsonl`\n",
    "\n",
    "### Next Steps:\n",
    "1. Download the final JSONL file\n",
    "2. Load it into your training pipeline\n",
    "3. Fine-tune your cognitive action recognition model\n",
    "\n",
    "**Note**: If generation was interrupted, you can resume from the last checkpoint!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
