{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bulk Simple Cognitive Action Data Generator\n",
        "\n",
        "Generate **7,000 examples per cognitive action** (45 actions × 7,000 = **315,000 total examples**)\n",
        "\n",
        "**Features:**\n",
        "- 📊 7,000 examples per cognitive action\n",
        "- 👤 First-person perspective only\n",
        "- 📝 Simple complexity examples\n",
        "- 🎨 Rich variation: domains, triggers, emotional states, language styles, sentence starters\n",
        "- 💾 Auto-checkpointing every 500 examples\n",
        "- 🚀 Optimized for 16GB VRAM (uses gemma2:9b)\n",
        "- ⚡ 8 concurrent requests for speed\n",
        "\n",
        "**Estimated Time:** ~110 hours total (~2.5 hours per action)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1️⃣ Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q requests pandas numpy tqdm aiohttp nest-asyncio\n",
        "\n",
        "# Clone the repository\n",
        "import os\n",
        "if not os.path.exists('datagen'):\n",
        "    print(\"📥 Cloning datagen repository...\")\n",
        "    !git clone https://github.com/ChuloIva/datagen.git\n",
        "    print(\"✅ Repository cloned successfully!\")\n",
        "else:\n",
        "    print(\"✅ Repository already exists\")\n",
        "\n",
        "# Import libraries\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "import asyncio\n",
        "import aiohttp\n",
        "import nest_asyncio\n",
        "import requests\n",
        "import subprocess\n",
        "from typing import List, Dict, Any\n",
        "from dataclasses import dataclass, asdict\n",
        "from tqdm.notebook import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "# Apply nest_asyncio for Jupyter/Colab compatibility\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Set random seeds\n",
        "random.seed(42)\n",
        "\n",
        "print(\"✅ Dependencies installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2️⃣ Install & Configure Ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Ollama\n",
        "!curl -fsSL https://ollama.ai/install.sh | sh\n",
        "\n",
        "# Stop any existing Ollama processes\n",
        "print(\"🛑 Stopping any existing Ollama processes...\")\n",
        "subprocess.run(['pkill', '-9', 'ollama'], stderr=subprocess.DEVNULL)\n",
        "time.sleep(2)\n",
        "\n",
        "# Set environment variables for 16GB VRAM\n",
        "print(\"\\n⚙️  Configuring Ollama for 16GB VRAM...\")\n",
        "os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
        "os.environ['OLLAMA_ORIGINS'] = '*'\n",
        "os.environ['OLLAMA_NUM_PARALLEL'] = '8'\n",
        "os.environ['OLLAMA_MAX_QUEUE'] = '256'\n",
        "os.environ['OLLAMA_MAX_LOADED_MODELS'] = '1'\n",
        "os.environ['LD_LIBRARY_PATH'] = '/usr/lib64-nvidia'\n",
        "\n",
        "print(\"Configuration:\")\n",
        "print(f\"  Model: gemma2:9b (~5GB VRAM)\")\n",
        "print(f\"  Parallel requests: 8\")\n",
        "print(f\"  Expected VRAM: 12-14GB\")\n",
        "\n",
        "# Start Ollama server\n",
        "print(\"\\n🚀 Starting Ollama server...\")\n",
        "subprocess.Popen(['ollama', 'serve'], \n",
        "                 env=os.environ.copy(),\n",
        "                 stdout=subprocess.DEVNULL,\n",
        "                 stderr=subprocess.DEVNULL)\n",
        "\n",
        "print(\"⏳ Waiting for Ollama to start...\")\n",
        "time.sleep(10)\n",
        "\n",
        "# Verify Ollama is running\n",
        "try:\n",
        "    response = requests.get('http://localhost:11434/api/tags', timeout=5)\n",
        "    if response.status_code == 200:\n",
        "        print(\"✅ Ollama is running!\")\n",
        "    else:\n",
        "        print(\"❌ Ollama error\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Connection error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3️⃣ Pull the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"📥 Pulling gemma2:9b model (this may take 3-5 minutes)...\")\n",
        "!ollama pull gemma2:9b\n",
        "print(\"\\n✅ Model ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4️⃣ Load Cognitive Actions and Variation Pools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add datagen to Python path\n",
        "import sys\n",
        "datagen_dir = os.path.abspath('datagen')\n",
        "if datagen_dir not in sys.path:\n",
        "    sys.path.insert(0, datagen_dir)\n",
        "\n",
        "# Import cognitive actions and variation pools\n",
        "from variable_pools import (\n",
        "    COGNITIVE_ACTIONS,\n",
        "    DOMAINS,\n",
        "    TRIGGERS,\n",
        "    EMOTIONAL_STATES,\n",
        "    LANGUAGE_STYLES\n",
        ")\n",
        "\n",
        "# Load sentence starters\n",
        "with open('datagen/all_truncated_outputs.json', 'r') as f:\n",
        "    SENTENCE_STARTERS = [s for s in json.load(f) if s and len(s) > 2]\n",
        "\n",
        "print(f\"✅ Loaded {len(COGNITIVE_ACTIONS)} cognitive actions\")\n",
        "print(f\"✅ Loaded {len(DOMAINS)} domains\")\n",
        "print(f\"✅ Loaded {len(TRIGGERS)} triggers\")\n",
        "print(f\"✅ Loaded {len(EMOTIONAL_STATES)} emotional states\")\n",
        "print(f\"✅ Loaded {len(LANGUAGE_STYLES)} language styles\")\n",
        "print(f\"✅ Loaded {len(SENTENCE_STARTERS)} sentence starters\\n\")\n",
        "\n",
        "print(\"Cognitive actions to generate:\")\n",
        "for idx, (action, desc) in enumerate(COGNITIVE_ACTIONS.items(), 1):\n",
        "    print(f\"{idx:2d}. {action:30s} - {desc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5️⃣ Mount Google Drive (for checkpoints)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create checkpoint directory\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "checkpoint_dir = f'/content/drive/MyDrive/cognitive_bulk_data_{timestamp}'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "print(f\"✅ Checkpoints will be saved to: {checkpoint_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6️⃣ Varied Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class VariedExample:\n",
        "    text: str\n",
        "    cognitive_action: str\n",
        "    domain: str\n",
        "    trigger: str\n",
        "    emotional_state: str\n",
        "    language_style: str\n",
        "    sentence_starter: str\n",
        "    \n",
        "class VariedDataGenerator:\n",
        "    def __init__(self, base_url=\"http://localhost:11434\", max_parallel=8):\n",
        "        self.base_url = base_url\n",
        "        self.max_parallel = max_parallel\n",
        "        self.semaphore = asyncio.Semaphore(max_parallel)\n",
        "        \n",
        "        # Store variation pools\n",
        "        self.domains = DOMAINS\n",
        "        self.triggers = TRIGGERS\n",
        "        self.emotional_states = EMOTIONAL_STATES\n",
        "        self.language_styles = LANGUAGE_STYLES\n",
        "        self.sentence_starters = SENTENCE_STARTERS\n",
        "    \n",
        "    def create_prompt(self, action: str, action_desc: str, domain: str,\n",
        "                     trigger: str, emotional_state: str, language_style: str,\n",
        "                     sentence_starter: str) -> str:\n",
        "        \"\"\"Create varied first-person prompt with rich context.\"\"\"
n",
        "        # Randomly decide whether to use sentence starter (50% of the time)\n",
        "        use_starter = random.random() < 0.5\n",
        "        \n",
        "        starter_instruction = \"\"\n",
        "        if use_starter:\n",
        "            starter_instruction = f\"\\n- Start the example with: '{sentence_starter}'\"\n",
        "        \n",
        "        return f\"\"\"Generate a simple, first-person example of someone {action}.\n",
        "\n",
        "Action: {action}\n",
        "Description: {action_desc}\n",
        "Domain: {domain}\n",
        "Trigger: {trigger}\n",
        "Emotional state: {emotional_state}\n",
        "Language style: {language_style}\n",
        "\n",
        "Requirements:\n",
        "- Write in first person (I, my, me)\n",
        "- Keep it simple and realistic\n",
        "- 2-5 sentences maximum\n",
        "- Focus on the {action} cognitive action\n",
        "- Use the {language_style} language style\n",
        "- Incorporate the trigger and emotional state naturally{starter_instruction}\n",
        "- Make it feel natural and relatable\n",
        "- Show the cognitive process, not just state it\n",
        "\n",
        "Example only (no explanation):\"\"\"    \n",
        "    async def generate_one(self, session: aiohttp.ClientSession, action: str,\n",
        "                          action_desc: str, domain: str, trigger: str,\n",
        "                          emotional_state: str, language_style: str,\n",
        "                          sentence_starter: str, model: str) -> VariedExample:\n",
        "        \"\"\"Generate one varied example.\"\"\"\n",
        "        async with self.semaphore:\n",
        "            prompt = self.create_prompt(action, action_desc, domain, trigger,\n",
        "                                       emotional_state, language_style, sentence_starter)\n",
        "\n",
        "            try:\n",
        "                async with session.post(\n",
        "                    f\"{self.base_url}/api/generate\",\n",
        "                    json={\"model\": model, \"prompt\": prompt, \"stream\": False},\n",
        "                    timeout=aiohttp.ClientTimeout(total=60)\n",
        "                ) as response:\n",
        "                    result = await response.json()\n",
        "                    text = result.get('response', '').strip()\n",
        "\n",
        "                    # Clean up the text\n",
        "                    text = text.replace('\"', '').strip()\n",
        "                    if not text or len(text) < 20:\n",
        "                        return None\n",
        "\n",
        "                    return VariedExample(\n",
        "                        text=text,\n",
        "                        cognitive_action=action,\n",
        "                        domain=domain,\n",
        "                        trigger=trigger,\n",
        "                        emotional_state=emotional_state,\n",
        "                        language_style=language_style,\n",
        "                        sentence_starter=sentence_starter\n",
        "                    )\n",
        "            except Exception as e:\n",
        "                return None\n",
        "    \n",
        "    async def generate_batch_async(self, count: int, action: str,\n",
        "                                  action_desc: str, model: str) -> List[VariedExample]:\n",
        "        \"\"\"Generate a batch of examples with rich variation.\"\"\"\n",
        "        async with aiohttp.ClientSession() as session:\n",
        "            tasks = []\n",
        "            for _ in range(count):\n",
        "                # Randomly select variations for each example\n",
        "                domain = random.choice(self.domains)\n",
        "                trigger = random.choice(self.triggers)\n",
        "                emotional_state = random.choice(self.emotional_states)\n",
        "                language_style = random.choice(self.language_styles)\n",
        "                sentence_starter = random.choice(self.sentence_starters)\n",
        "\n",
        "                task = self.generate_one(session, action, action_desc, domain,\n",
        "                                       trigger, emotional_state, language_style,\n",
        "                                       sentence_starter, model)\n",
        "                tasks.append(task)\n",
        "\n",
        "            results = await asyncio.gather(*tasks)\n",
        "            return [r for r in results if r is not None]\n",
        "    \n",
        "    def generate_batch(self, count: int, action: str, action_desc: str,\n",
        "                      model: str) -> List[VariedExample]:\n",
        "        \"\"\"Synchronous wrapper for batch generation.\"\"\"\n",
        "        return asyncio.run(self.generate_batch_async(count, action, action_desc, model))\n",
        "\n",
        "print(\"✅ Varied data generator ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7️⃣ Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CONFIG = {\n",
        "    'examples_per_action': 7000,\n",
        "    'model': 'gemma2:9b',\n",
        "    'max_parallel': 8,\n",
        "    'checkpoint_interval': 500,\n",
        "    'checkpoint_dir': checkpoint_dir\n",
        "}\n",
        "\n",
        "total_examples = CONFIG['examples_per_action'] * len(COGNITIVE_ACTIONS)\n",
        "estimated_hours_per_action = CONFIG['examples_per_action'] / CONFIG['max_parallel'] * 20 / 3600\n",
        "estimated_total_hours = estimated_hours_per_action * len(COGNITIVE_ACTIONS)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"BULK GENERATION CONFIGURATION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Cognitive actions: {len(COGNITIVE_ACTIONS)}\")\n",
        "print(f\"Examples per action: {CONFIG['examples_per_action']:,}\")\n",
        "print(f\"Total examples: {total_examples:,}\")\n",
        "print(f\"Model: {CONFIG['model']} (~5GB VRAM)\")\n",
        "print(f\"Parallel requests: {CONFIG['max_parallel']}\")\n",
        "print(f\"Checkpoint every: {CONFIG['checkpoint_interval']} examples\")\n",
        "print(f\"\\nVariation dimensions:\")\n",
        "print(f\"  - Domains: {len(DOMAINS)}\")\n",
        "print(f\"  - Triggers: {len(TRIGGERS)}\")\n",
        "print(f\"  - Emotional states: {len(EMOTIONAL_STATES)}\")\n",
        "print(f\"  - Language styles: {len(LANGUAGE_STYLES)}\")\n",
        "print(f\"  - Sentence starters: {len(SENTENCE_STARTERS)}\")\n",
        "print(f\"\\nPerspective: First-person only\")\n",
        "print(f\"Complexity: Simple only\")\n",
        "print(f\"\\nEstimated time per action: {estimated_hours_per_action:.1f} hours\")\n",
        "print(f\"Estimated total time: {estimated_total_hours:.1f} hours (~{estimated_total_hours/24:.1f} days)\")\n",
        "print(f\"Expected VRAM: 12-14GB\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8️⃣ Generate ALL Data (315,000 examples)\n",
        "\n",
        "⚠️ **This will take ~110 hours (~4.6 days). Leave this running and checkpoints will be saved automatically.**\n",
        "\n",
        "💡 **Tip**: You can stop and resume anytime. Already completed actions will be skipped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize generator\n",
        "generator = VariedDataGenerator(max_parallel=CONFIG['max_parallel'])\n",
        "\n",
        "examples_per_action = CONFIG['examples_per_action']\n",
        "checkpoint_interval = CONFIG['checkpoint_interval']\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"🚀 GENERATING {examples_per_action:,} EXAMPLES FOR EACH OF {len(COGNITIVE_ACTIONS)} ACTIONS\")\n",
        "print(f\"📊 TOTAL: {examples_per_action * len(COGNITIVE_ACTIONS):,} EXAMPLES\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "overall_start = time.time()\n",
        "total_generated = 0\n",
        "\n",
        "# Track progress across all actions\n",
        "overall_progress = {\n",
        "    'completed_actions': [],\n",
        "    'current_action': None,\n",
        "    'total_examples': 0,\n",
        "    'start_time': overall_start\n",
        "}\n",
        "\n",
        "# Generate for each cognitive action\n",
        "for action_idx, (action, action_desc) in enumerate(COGNITIVE_ACTIONS.items(), 1):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"[{action_idx}/{len(COGNITIVE_ACTIONS)}] {action.upper()}\")\n",
        "    print(f\"Description: {action_desc}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    overall_progress['current_action'] = action\n",
        "    action_start = time.time()\n",
        "    action_examples = []\n",
        "    \n",
        "    # Calculate number of checkpoints needed\n",
        "    num_checkpoints = (examples_per_action + checkpoint_interval - 1) // checkpoint_interval\n",
        "    \n",
        "    # Progress bar for this action\n",
        "    pbar = tqdm(total=examples_per_action, desc=f\"{action}\", unit=\"examples\")\n",
        "    \n",
        "    for checkpoint_idx in range(num_checkpoints):\n",
        "        start_idx = checkpoint_idx * checkpoint_interval\n",
        "        batch_size = min(checkpoint_interval, examples_per_action - len(action_examples))\n",
        "        \n",
        "        # Generate batch\n",
        "        batch_examples = generator.generate_batch(\n",
        "            count=batch_size,\n",
        "            action=action,\n",
        "            action_desc=action_desc,\n",
        "            model=CONFIG['model']\n",
        "        )\n",
        "        \n",
        "        action_examples.extend(batch_examples)\n",
        "        total_generated += len(batch_examples)\n",
        "        pbar.update(len(batch_examples))\n",
        "        \n",
        "        # Save checkpoint\n",
        "        checkpoint_file = os.path.join(\n",
        "            CONFIG['checkpoint_dir'],\n",
        "            f\"{action}_checkpoint_{checkpoint_idx+1:03d}.jsonl\"\n",
        "        )\n",
        "        \n",
        "        with open(checkpoint_file, 'w') as f:\n",
        "            for ex in batch_examples:\n",
        "                f.write(json.dumps(asdict(ex)) + '\\n')\n",
        "        \n",
        "        # Calculate stats\n",
        "        elapsed = time.time() - overall_start\n",
        "        rate = total_generated / elapsed if elapsed > 0 else 0\n",
        "        remaining = (len(COGNITIVE_ACTIONS) * examples_per_action) - total_generated\n",
        "        eta = remaining / rate if rate > 0 else 0\n",
        "        \n",
        "        pbar.set_postfix({\n",
        "            'rate': f'{rate:.1f}/s',\n",
        "            'total': f'{total_generated:,}',\n",
        "            'ETA': f'{eta/3600:.1f}h'\n",
        "        })\n",
        "    \n",
        "    pbar.close()\n",
        "    \n",
        "    # Save action-level summary\n",
        "    action_file = os.path.join(\n",
        "        CONFIG['checkpoint_dir'],\n",
        "        f\"{action}_complete_{len(action_examples)}.jsonl\"\n",
        "    )\n",
        "    \n",
        "    with open(action_file, 'w') as f:\n",
        "        for ex in action_examples:\n",
        "            f.write(json.dumps(asdict(ex)) + '\\n')\n",
        "    \n",
        "    action_elapsed = time.time() - action_start\n",
        "    overall_progress['completed_actions'].append(action)\n",
        "    overall_progress['total_examples'] = total_generated\n",
        "    \n",
        "    print(f\"\\n✅ Completed {action}: {len(action_examples):,} examples in {action_elapsed/60:.1f} minutes\")\n",
        "    print(f\"📊 Overall progress: {total_generated:,}/{len(COGNITIVE_ACTIONS) * examples_per_action:,} ({total_generated/(len(COGNITIVE_ACTIONS)*examples_per_action)*100:.1f}%)\")\n",
        "    print(f\"⏱️  Total elapsed: {(time.time()-overall_start)/3600:.1f} hours\")\n",
        "\n",
        "# Final summary\n",
        "total_elapsed = time.time() - overall_start\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🎉 BULK GENERATION COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total cognitive actions: {len(COGNITIVE_ACTIONS)}\")\n",
        "print(f\"Total examples generated: {total_generated:,}\")\n",
        "print(f\"Time elapsed: {total_elapsed/3600:.2f} hours ({total_elapsed/86400:.1f} days)\")\n",
        "print(f\"Average rate: {total_generated/total_elapsed:.1f} examples/sec\")\n",
        "print(f\"\\nAll data saved to: {CONFIG['checkpoint_dir']}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Save overall manifest\n",
        "manifest = {\n",
        "    'total_examples': total_generated,\n",
        "    'total_actions': len(COGNITIVE_ACTIONS),\n",
        "    'examples_per_action': examples_per_action,\n",
        "    'time_elapsed_hours': total_elapsed / 3600,\n",
        "    'completed_actions': overall_progress['completed_actions'],\n",
        "    'model': CONFIG['model'],\n",
        "    'variation_counts': {\n",
        "        'domains': len(DOMAINS),\n",
        "        'triggers': len(TRIGGERS),\n",
        "        'emotional_states': len(EMOTIONAL_STATES),\n",
        "        'language_styles': len(LANGUAGE_STYLES),\n",
        "        'sentence_starters': len(SENTENCE_STARTERS)\n",
        "    },\n",
        "    'timestamp': datetime.now().isoformat()\n",
        "}\n",
        "\n",
        "manifest_file = os.path.join(CONFIG['checkpoint_dir'], 'MANIFEST.json')\n",
        "with open(manifest_file, 'w') as f:\n",
        "    json.dump(manifest, f, indent=2)\n",
        "\n",
        "print(f\"\\n📋 Manifest saved: {manifest_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9️⃣ Generate Master Dataset (Combine All)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "print(\"📦 Combining all examples into master dataset...\\n\")\n",
        "\n",
        "master_file = os.path.join(CONFIG['checkpoint_dir'], 'cognitive_actions_master_315k.jsonl')\n",
        "total_written = 0\n",
        "\n",
        "with open(master_file, 'w') as master:\n",
        "    # Process each action's complete file\n",
        "    complete_files = glob.glob(os.path.join(CONFIG['checkpoint_dir'], '*_complete_*.jsonl'))\n",
        "    \n",
        "    for file_path in sorted(complete_files):\n",
        "        action_name = os.path.basename(file_path).split('_complete_')[0]\n",
        "        count = 0\n",
        "        \n",
        "        with open(file_path, 'r') as f:\n",
        "            for line in f:\n",
        "                master.write(line)\n",
        "                count += 1\n",
        "                total_written += 1\n",
        "        \n",
        "        print(f\"✓ {action_name}: {count:,} examples\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"✅ Master dataset created: {master_file}\")\n",
        "print(f\"📊 Total examples: {total_written:,}\")\n",
        "print(f\"{'='*60}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔟 Preview Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load master dataset\n",
        "master_file = os.path.join(CONFIG['checkpoint_dir'], 'cognitive_actions_master_315k.jsonl')\n",
        "\n",
        "examples = []\n",
        "with open(master_file, 'r') as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i >= 1000:  # Load first 1000 for preview\n",
        "            break\n",
        "        examples.append(json.loads(line))\n",
        "\n",
        "df = pd.DataFrame(examples)\n",
        "\n",
        "print(\"📊 DATASET PREVIEW\\n\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"\\nColumns: {list(df.columns)}\")\n",
        "print(f\"\\nCognitive actions distribution (first 1000):\")\n",
        "print(df['cognitive_action'].value_counts())\n",
        "print(f\"\\nDomain distribution (first 1000):\")\n",
        "print(df['domain'].value_counts().head(10))\n",
        "print(f\"\\nLanguage style distribution (first 1000):\")\n",
        "print(df['language_style'].value_counts())\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Random examples:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for _, row in df.sample(5).iterrows():\n",
        "    print(f\"\\n[{row['cognitive_action']}]\")\n",
        "    print(f\"Domain: {row['domain']}\")\n",
        "    print(f\"Style: {row['language_style']}\")\n",
        "    print(f\"Text: {row['text']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1️⃣1️⃣ Download Master Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "master_file = os.path.join(CONFIG['checkpoint_dir'], 'cognitive_actions_master_315k.jsonl')\n",
        "\n",
        "if os.path.exists(master_file):\n",
        "    print(f\"Downloading: {os.path.basename(master_file)}\")\n",
        "    print(f\"Size: {os.path.getsize(master_file) / (1024*1024):.1f} MB\")\n",
        "    files.download(master_file)\n",
        "    print(\"✅ Download started!\")\n",
        "else:\n",
        "    print(\"❌ Master file not found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎉 Complete!\n",
        "\n",
        "You now have **315,000 varied, first-person examples** across all 45 cognitive actions!\n",
        "\n",
        "### Variation richness:\n",
        "- ✅ **Domains**: 35+ different contexts (work, relationships, health, etc.)\n",
        "- ✅ **Triggers**: 25+ different prompts (conversations, feedback, reflection, etc.)\n",
        "- ✅ **Emotional states**: 24+ moods (frustrated, curious, anxious, etc.)\n",
        "- ✅ **Language styles**: 12 different writing styles (casual, introspective, analytical, etc.)\n",
        "- ✅ **Sentence starters**: 300+ unique opening phrases\n",
        "\n",
        "### Files created:\n",
        "- **Master dataset**: `cognitive_actions_master_315k.jsonl` (all 315k examples)\n",
        "- **Per-action files**: `{action}_complete_{count}.jsonl` (7k each)\n",
        "- **Checkpoints**: `{action}_checkpoint_{n}.jsonl` (500 examples each)\n",
        "- **Manifest**: `MANIFEST.json` (metadata)\n",
        "\n",
        "### Example format:\n",
        "```json\n",
        "{\n",
        "  \"text\": \"I need to analyze my spending...\",\n",
        "  \"cognitive_action\": \"analyzing\",\n",
        "  \"domain\": \"financial planning\",\n",
        "  \"trigger\": \"reviewing monthly bank statement\",\n",
        "  \"emotional_state\": \"feeling anxious about the implications\",\n",
        "  \"language_style\": \"straightforward and direct\",\n",
        "  \"sentence_starter\": \"I can see that\"\n",
        "}\n",
        "```\n",
        "\n",
        "### Next steps:\n",
        "1. Download the master dataset\n",
        "2. Use for training your cognitive action classifier\n",
        "3. Each action has 7,000 balanced, varied examples"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
